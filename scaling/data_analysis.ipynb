{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2ORC Dataset Analysis Notebook\n",
    "\n",
    "This notebook provides tools for analyzing the processed Parquet files from the ETL pipeline.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Make sure you're using the `nvidia_impact_env` conda environment for GPU acceleration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/miniconda3/envs/nvidia_impact_env/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/home/asus/miniconda3/envs/nvidia_impact_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "Device: NVIDIA GB10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/miniconda3/envs/nvidia_impact_env/lib/python3.10/site-packages/torch/cuda/__init__.py:235: UserWarning: \n",
      "NVIDIA GB10 with CUDA capability sm_121 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_89 sm_90 compute_90.\n",
      "If you want to use the NVIDIA GB10 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & Setup\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "# Check for GPU\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Config\n",
    "INPUT_DIR = \"processed_parquet\"\n",
    "OUTPUT_DIR = \"evaluation_results\"\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'  # Fast, effective for semantic classification\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define Extraction Logic\n",
    "\n",
    "# --- 1. HARD SIGNALS (Regex Patterns) ---\n",
    "# These extract specific strings for lists/booleans\n",
    "REGEX_PATTERNS = {\n",
    "    \"frameworks\": {\n",
    "        \"PyTorch\": r\"\\b(pytorch|torch)\\b\",\n",
    "        \"TensorFlow\": r\"\\b(tensorflow|keras)\\b\",\n",
    "        \"JAX\": r\"\\b(jax|flax)\\b\",\n",
    "        \"Scikit-Learn\": r\"\\b(scikit-learn|sklearn)\\b\",\n",
    "        \"HuggingFace\": r\"\\b(huggingface|transformers)\\b\",\n",
    "        \"FastAI\": r\"\\b(fastai)\\b\"\n",
    "    },\n",
    "    \"compute\": {\n",
    "        \"NVIDIA GPU\": r\"\\b(nvidia|gpu|cuda|a100|v100|h100|rtx|geforce)\\b\",\n",
    "        \"TPU\": r\"\\b(tpu|tensor processing unit)\\b\",\n",
    "        \"HPC/Cluster\": r\"\\b(hpc|supercomputer|cluster|slurm)\\b\"\n",
    "    },\n",
    "    \"repo_type\": {\n",
    "        \"GitHub\": r\"github\\.com\",\n",
    "        \"GitLab\": r\"gitlab\\.com\",\n",
    "        \"BitBucket\": r\"bitbucket\\.org\",\n",
    "        \"Zenodo\": r\"zenodo\",\n",
    "        \"FigShare\": r\"figshare\"\n",
    "    },\n",
    "    \"identifiers\": {\n",
    "        \"clinical_trial\": r\"\\b(NCT\\d{8}|ISRCTN\\d{8})\\b\",\n",
    "        \"patent\": r\"\\b(US\\d{7,}|WO\\d{4}\\d{6})\\b\",\n",
    "        \"grant\": r\"\\b(NSF|NIH|ERC|grant number)\\b\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- 2. SEMANTIC ANCHORS (Vector Descriptions) ---\n",
    "# We compare paper abstracts to these descriptions to determine \"Levels\"\n",
    "ANCHOR_TEXTS = {\n",
    "    \"adoption_level\": {\n",
    "        \"core\": \"novel machine learning algorithm model architecture loss function theoretical deep learning\",\n",
    "        \"substantial\": \"deep learning implementation neural network training fine-tuning transformer architecture\",\n",
    "        \"moderate\": \"applied machine learning random forest support vector machine classification regression analysis\",\n",
    "        \"minimal\": \"statistical analysis t-test correlation linear regression pca clustering\",\n",
    "        \"none\": \"qualitative analysis literature review theoretical derivation manual annotation\"\n",
    "    },\n",
    "    \"impact_scope\": {\n",
    "        \"transformative\": \"paradigm shift breakthrough discovery universal application fundamental change\",\n",
    "        \"broad\": \"wide application cross-domain utility standard benchmark widespread adoption\",\n",
    "        \"moderate\": \"improvement baseline optimization specific domain incremental advance\",\n",
    "        \"narrow\": \"case study preliminary result specific implementation single dataset\"\n",
    "    },\n",
    "    \"replication_feasibility\": {\n",
    "        \"straightforward\": \"source code available public dataset detailed methodology reproducible\",\n",
    "        \"moderate\": \"methodology described parameters listed some code available\",\n",
    "        \"difficult\": \"complex pipeline custom hardware missing parameters proprietary data\",\n",
    "        \"not_feasible\": \"proprietary code closed data insufficient detail\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded and anchors vectorised.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize Model\n",
    "model = SentenceTransformer(MODEL_NAME, device='cuda')\n",
    "\n",
    "# Pre-compute anchor vectors for fast comparison\n",
    "anchor_vectors = {}\n",
    "for category, options in ANCHOR_TEXTS.items():\n",
    "    anchor_vectors[category] = {}\n",
    "    for label, text in options.items():\n",
    "        # Encode and keep on CPU as numpy for fast mapping later (or move to GPU if using CuPy)\n",
    "        anchor_vectors[category][label] = model.encode(text, normalize_embeddings=True)\n",
    "\n",
    "print(\"✅ Model loaded and anchors vectorised.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Core Extraction Function (CORRECTED)\n",
    "def extract_paper_evaluation(row, embedding, vector_anchors):\n",
    "    # --- 1. PREPARE TEXT ---\n",
    "    full_text = str(row.get('text', '')) # KEEP EVERYTHING\n",
    "    full_text_lower = full_text.lower()\n",
    "    \n",
    "    # --- 2. VECTOR MATH (Using Pre-Computed Embedding) ---\n",
    "    # Note: We assume 'embedding' was generated from the first ~2000 chars\n",
    "    # in the main loop to save GPU compute.\n",
    "    \n",
    "    # Helper to find closest semantic match\n",
    "    def get_best_match(anchors_dict, paper_vec):\n",
    "        best_score = -1\n",
    "        best_label = \"none\"\n",
    "        for label, anchor_vec in anchors_dict.items():\n",
    "            score = np.dot(paper_vec, anchor_vec)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_label = label\n",
    "        return best_label\n",
    "\n",
    "    # --- 3. REGEX EXTRACTIONS (Scanning FULL TEXT) ---\n",
    "    # We scan the ENTIRE string now, catching Appendices/References\n",
    "    \n",
    "    found_frameworks = [k for k, v in REGEX_PATTERNS['frameworks'].items() if re.search(v, full_text_lower)]\n",
    "    found_compute = [k for k, v in REGEX_PATTERNS['compute'].items() if re.search(v, full_text_lower)]\n",
    "    \n",
    "    # Critical Fix: Repository links often appear at the very end\n",
    "    found_repos = [k for k, v in REGEX_PATTERNS['repo_type'].items() if re.search(v, full_text_lower)]\n",
    "    \n",
    "    # Identifiers\n",
    "    found_trials = re.findall(REGEX_PATTERNS['identifiers']['clinical_trial'], full_text)\n",
    "    found_patents = re.findall(REGEX_PATTERNS['identifiers']['patent'], full_text)\n",
    "    \n",
    "    # --- 4. SEMANTIC CLASSIFICATIONS ---\n",
    "    adoption_level = get_best_match(vector_anchors['adoption_level'], embedding)\n",
    "    impact_scope = get_best_match(vector_anchors['impact_scope'], embedding)\n",
    "    repl_feasibility = get_best_match(vector_anchors['replication_feasibility'], embedding)\n",
    "\n",
    "    # --- 5. CONSTRUCT DICTIONARY ---\n",
    "    evaluation = {\n",
    "        \"paper_id\": str(row['paper_id']),\n",
    "        \"field\": str(row['primary_field']),\n",
    "        \"publication_date\": str(row['year']),\n",
    "        \n",
    "        \"ml_adoption\": {\n",
    "            \"ml_frameworks_mentioned\": found_frameworks,\n",
    "            \"specific_models_architectures\": [], \n",
    "            \"compute_resources_mentioned\": found_compute,\n",
    "            \"datasets_referenced\": [], \n",
    "            \"ml_libraries_tools\": found_frameworks, \n",
    "            \"ml_adoption_level\": adoption_level,\n",
    "            \"ml_application_domain\": str(row['primary_field']),\n",
    "            \"ml_method_primary\": None,\n",
    "            \"integration_with_traditional_methods\": False\n",
    "        },\n",
    "        \"reproducibility\": {\n",
    "            \"code_availability_mentioned\": len(found_repos) > 0 or \"code available\" in full_text_lower,\n",
    "            \"code_repository_type\": found_repos[0] if found_repos else None,\n",
    "            \"data_availability_mentioned\": \"data available\" in full_text_lower or \"zenodo\" in full_text_lower,\n",
    "            \"data_sharing_statement\": None,\n",
    "            # Heuristic: Detailed methodology usually means longer text\n",
    "            \"methodology_detail_level\": \"detailed\" if len(full_text) > 25000 else \"moderate\",\n",
    "            \"hyperparameters_specified\": \"hyperparameter\" in full_text_lower,\n",
    "            \"computational_environment_described\": len(found_compute) > 0,\n",
    "            \"preprocessing_steps_detailed\": \"preprocessing\" in full_text_lower,\n",
    "            \"statistical_methods_described\": \"statistical\" in full_text_lower or \"p-value\" in full_text_lower,\n",
    "            \"replication_feasibility\": repl_feasibility\n",
    "        },\n",
    "        \"research_outcomes\": {\n",
    "            \"mentions_clinical_trials\": len(found_trials) > 0,\n",
    "            \"clinical_trial_identifiers\": list(set(found_trials)),\n",
    "            \"mentions_patents\": len(found_patents) > 0,\n",
    "            \"patent_numbers\": list(set(found_patents)),\n",
    "            \"mentions_corrections\": \"correction\" in full_text_lower[:1000], # Corrections usually in title/header\n",
    "            \"mentions_retractions\": \"retraction\" in full_text_lower[:1000],\n",
    "            \"validation_type\": [],\n",
    "            \"real_world_application_mentioned\": impact_scope in [\"transformative\", \"broad\"],\n",
    "            \"commercialization_mentioned\": \"commercial\" in full_text_lower,\n",
    "            \"regulatory_approval_mentioned\": \"fda\" in full_text_lower or \"approved\" in full_text_lower\n",
    "        },\n",
    "        \"impact_indicators\": {\n",
    "            \"claims_novelty\": \"novel\" in full_text_lower or \"first time\" in full_text_lower,\n",
    "            \"claims_improvement_over_existing\": \"outperform\" in full_text_lower or \"better than\" in full_text_lower,\n",
    "            \"quantitative_improvements_mentioned\": \"%\" in full_text_lower or \"accuracy\" in full_text_lower,\n",
    "            \"comparison_to_baseline\": \"baseline\" in full_text_lower,\n",
    "            \"mentions_policy_implications\": \"policy\" in full_text_lower,\n",
    "            \"mentions_clinical_guidelines\": \"guideline\" in full_text_lower,\n",
    "            \"mentions_media_coverage\": False,\n",
    "            \"collaboration_indicators\": [],\n",
    "            \"funding_sources_mentioned\": [],\n",
    "            \"potential_impact_scope\": impact_scope\n",
    "        },\n",
    "        \"overall_assessment\": f\"Paper in {row['primary_field']} ({row['year']}) with {adoption_level} ML adoption.\",\n",
    "        \"confidence_score\": \"medium\",\n",
    "        \"notes\": \"Generated by NVIDIA Impact Engine\"\n",
    "    }\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2396 files to process.\n",
      "✅ [1/2396] Saved 2 evals to chunk_test_01250.jsonl\n",
      "✅ [2/2396] Saved 1 evals to chunk_test_01260.jsonl\n",
      "✅ [3/2396] Saved 1 evals to chunk_test_01264.jsonl\n",
      "✅ [4/2396] Saved 1 evals to chunk_test_01265.jsonl\n",
      "✅ [5/2396] Saved 2 evals to chunk_test_01266.jsonl\n",
      "✅ [6/2396] Saved 1 evals to chunk_test_01268.jsonl\n",
      "✅ [7/2396] Saved 1 evals to chunk_test_01272.jsonl\n",
      "✅ [8/2396] Saved 1 evals to chunk_test_01280.jsonl\n",
      "✅ [9/2396] Saved 1 evals to chunk_test_01281.jsonl\n",
      "✅ [10/2396] Saved 1 evals to chunk_test_01282.jsonl\n",
      "✅ [11/2396] Saved 1 evals to chunk_test_01283.jsonl\n",
      "✅ [12/2396] Saved 2 evals to chunk_test_01286.jsonl\n",
      "✅ [13/2396] Saved 6 evals to chunk_test_01289.jsonl\n",
      "✅ [14/2396] Saved 7 evals to chunk_test_01290.jsonl\n",
      "✅ [15/2396] Saved 8 evals to chunk_test_01291.jsonl\n",
      "✅ [16/2396] Saved 13 evals to chunk_test_01292.jsonl\n",
      "✅ [17/2396] Saved 19 evals to chunk_test_01293.jsonl\n",
      "✅ [18/2396] Saved 22 evals to chunk_test_01294.jsonl\n",
      "✅ [19/2396] Saved 28 evals to chunk_test_01295.jsonl\n",
      "✅ [20/2396] Saved 46 evals to chunk_test_01296.jsonl\n",
      "✅ [21/2396] Saved 68 evals to chunk_test_01297.jsonl\n",
      "✅ [22/2396] Saved 98 evals to chunk_test_01298.jsonl\n",
      "✅ [23/2396] Saved 170 evals to chunk_test_01299.jsonl\n",
      "✅ [24/2396] Saved 155 evals to chunk_test_01300.jsonl\n",
      "✅ [25/2396] Saved 118 evals to chunk_test_01301.jsonl\n",
      "✅ [26/2396] Saved 1 evals to chunk_test_01317.jsonl\n",
      "✅ [27/2396] Saved 2 evals to chunk_test_01336.jsonl\n",
      "✅ [28/2396] Saved 1 evals to chunk_test_01337.jsonl\n",
      "✅ [29/2396] Saved 1 evals to chunk_test_01341.jsonl\n",
      "✅ [30/2396] Saved 1 evals to chunk_test_01342.jsonl\n",
      "✅ [31/2396] Saved 1 evals to chunk_test_01344.jsonl\n",
      "✅ [32/2396] Saved 2 evals to chunk_test_01345.jsonl\n",
      "✅ [33/2396] Saved 3 evals to chunk_test_01346.jsonl\n",
      "✅ [34/2396] Saved 1 evals to chunk_test_01347.jsonl\n",
      "✅ [35/2396] Saved 7 evals to chunk_test_01348.jsonl\n",
      "✅ [36/2396] Saved 7 evals to chunk_test_01349.jsonl\n",
      "✅ [37/2396] Saved 5 evals to chunk_test_01350.jsonl\n",
      "✅ [38/2396] Saved 16 evals to chunk_test_01351.jsonl\n",
      "✅ [39/2396] Saved 12 evals to chunk_test_01352.jsonl\n",
      "✅ [40/2396] Saved 13 evals to chunk_test_01353.jsonl\n",
      "✅ [41/2396] Saved 11 evals to chunk_test_01354.jsonl\n",
      "✅ [42/2396] Saved 2 evals to chunk_test_01355.jsonl\n",
      "✅ [43/2396] Saved 2 evals to chunk_test_01356.jsonl\n",
      "✅ [44/2396] Saved 5 evals to chunk_test_01357.jsonl\n",
      "✅ [45/2396] Saved 2 evals to chunk_test_01358.jsonl\n",
      "✅ [46/2396] Saved 4 evals to chunk_test_01359.jsonl\n",
      "✅ [47/2396] Saved 6 evals to chunk_test_01360.jsonl\n",
      "✅ [48/2396] Saved 1 evals to chunk_test_01361.jsonl\n",
      "✅ [49/2396] Saved 3 evals to chunk_test_01362.jsonl\n",
      "✅ [50/2396] Saved 3 evals to chunk_test_01363.jsonl\n",
      "✅ [51/2396] Saved 4 evals to chunk_test_01364.jsonl\n",
      "✅ [52/2396] Saved 3 evals to chunk_test_01365.jsonl\n",
      "✅ [53/2396] Saved 6 evals to chunk_test_01366.jsonl\n",
      "✅ [54/2396] Saved 8 evals to chunk_test_01367.jsonl\n",
      "✅ [55/2396] Saved 5 evals to chunk_test_01368.jsonl\n",
      "✅ [56/2396] Saved 8 evals to chunk_test_01369.jsonl\n",
      "✅ [57/2396] Saved 4 evals to chunk_test_01370.jsonl\n",
      "✅ [58/2396] Saved 3 evals to chunk_test_01371.jsonl\n",
      "✅ [59/2396] Saved 4 evals to chunk_test_01372.jsonl\n",
      "✅ [60/2396] Saved 4 evals to chunk_test_01373.jsonl\n",
      "✅ [61/2396] Saved 7 evals to chunk_test_01374.jsonl\n",
      "✅ [62/2396] Saved 6 evals to chunk_test_01375.jsonl\n",
      "✅ [63/2396] Saved 10 evals to chunk_test_01376.jsonl\n",
      "✅ [64/2396] Saved 7 evals to chunk_test_01377.jsonl\n",
      "✅ [65/2396] Saved 9 evals to chunk_test_01378.jsonl\n",
      "✅ [66/2396] Saved 10 evals to chunk_test_01379.jsonl\n",
      "✅ [67/2396] Saved 7 evals to chunk_test_01380.jsonl\n",
      "✅ [68/2396] Saved 14 evals to chunk_test_01381.jsonl\n",
      "✅ [69/2396] Saved 13 evals to chunk_test_01382.jsonl\n",
      "✅ [70/2396] Saved 14 evals to chunk_test_01383.jsonl\n",
      "✅ [71/2396] Saved 16 evals to chunk_test_01384.jsonl\n",
      "✅ [72/2396] Saved 14 evals to chunk_test_01385.jsonl\n",
      "✅ [73/2396] Saved 23 evals to chunk_test_01386.jsonl\n",
      "✅ [74/2396] Saved 16 evals to chunk_test_01387.jsonl\n",
      "✅ [75/2396] Saved 16 evals to chunk_test_01388.jsonl\n",
      "✅ [76/2396] Saved 42 evals to chunk_test_01389.jsonl\n",
      "✅ [77/2396] Saved 35 evals to chunk_test_01390.jsonl\n",
      "✅ [78/2396] Saved 40 evals to chunk_test_01391.jsonl\n",
      "✅ [79/2396] Saved 36 evals to chunk_test_01392.jsonl\n",
      "✅ [80/2396] Saved 54 evals to chunk_test_01393.jsonl\n",
      "✅ [81/2396] Saved 64 evals to chunk_test_01394.jsonl\n",
      "✅ [82/2396] Saved 88 evals to chunk_test_01395.jsonl\n",
      "✅ [83/2396] Saved 108 evals to chunk_test_01396.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Run Processing Loop\n",
    "parquet_files = sorted(glob.glob(f\"{INPUT_DIR}/*.parquet\"))\n",
    "print(f\"Found {len(parquet_files)} files to process.\")\n",
    "\n",
    "for i, file_path in enumerate(parquet_files):\n",
    "    output_path = f\"{OUTPUT_DIR}/{os.path.basename(file_path).replace('.parquet', '.jsonl')}\"\n",
    "    if os.path.exists(output_path):\n",
    "        continue # Skip if done\n",
    "        \n",
    "    try:\n",
    "        # Load Parquet (Pandas for row iteration comfort, or cuDF if logic handles it)\n",
    "        # Using Pandas here for loop simplicity with complex dict creation\n",
    "        df = pd.read_parquet(file_path)\n",
    "        \n",
    "        if len(df) == 0: continue\n",
    "\n",
    "        # Vectorize text batch (GPU)\n",
    "        # We slice to 1000 chars for semantic vectorization (standard for BERT)\n",
    "        texts = df['text'].fillna(\"\").astype(str).str.slice(0, 1000).tolist()\n",
    "        embeddings = model.encode(texts, batch_size=64, show_progress_bar=False)\n",
    "        \n",
    "        # Build Results\n",
    "        results = []\n",
    "        for idx, row in df.iterrows():\n",
    "            eval_dict = extract_paper_evaluation(row, embeddings[idx], anchor_vectors)\n",
    "            results.append(eval_dict)\n",
    "            \n",
    "        # Save JSONL\n",
    "        with open(output_path, 'w') as f:\n",
    "            for item in results:\n",
    "                f.write(json.dumps(item) + \"\\n\")\n",
    "                \n",
    "        print(f\"✅ [{i+1}/{len(parquet_files)}] Saved {len(results)} evals to {os.path.basename(output_path)}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del df, texts, embeddings, results\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error on {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
